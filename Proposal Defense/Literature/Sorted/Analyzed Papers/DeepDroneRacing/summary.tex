
Challenges
\begin{itemize}
    \item unreliable state estimation
    \item optimal reaction to dynamically changing environment
    \item real time coupling of perception and action
    \item severe resource constraints
    \item fully autonomous racing drone
    \begin{itemize}
        \item dynamic modeling
        \item onboard perception
        \item localization and mapping
        \item trajectory generation
        \item optimal control
    \end{itemize}
    \item high speed (motion blurr, lighting conditions, perceptual aliasing)
    \item state-of-the-art estimation pipelines may require expensive sensors, have high computational costs, be subject to drift due to compressed maps
\end{itemize}

Autonomous, vision-based drone racing with possibly moving gates
\begin{itemize}
    \item Convolutional neural network
    \begin{itemize}
        \item Maps raw images into a waypoint and desired speed        
    \end{itemize}
    \item state-of-the-art path-planning and control system
    \begin{itemize}
        \item generates minimum-jerk trajectory segment with corresponding motor commands        
    \end{itemize}
    \item does not require explicit map
    \item runs fully onboard
\end{itemize}

Range of application
\begin{itemize}
    \item quick and safe flight through complex environments
    \begin{itemize}
        \item disaster response
        \item aerial delivery
        \item inspection of complex structures 
    \end{itemize}
\end{itemize}

Approaches for atonomous racing drones
\begin{itemize}
    \item accurately track a precomputed global trajectory passig through all gates
    \begin{itemize}
        \item requires highly accurate state estimation
        \item simultaneous localization and mapping (SLAM) systems can provide accurate pose estimations against a previously generated, globally consistent map.
        \begin{itemize}
            \item may fail when map was created in significantly different conditions
            \item may fail during periods of high acceleration (motion blurr, loss of feature tracking)
            \item enforcing global consistency leads to increased computational demands and difficulties in coping with dynamic environments
            \item enables navigation only in predominantly static worlds, waypoints and collision free trajectories can be statically defined
        \end{itemize}        
    \end{itemize}    
\end{itemize}


Method
\begin{itemize}
    \item perception: CNN
    \begin{itemize}
        \item input: raw single image (300 x 200 RGB) from foward-facing onboard camera 
        \item output: goal direction in local normalized image coordinates $\vec x \in [-1, 1]^2$ + normalized desired navigation speed $v\in [0, 1]$
        \item employs ResNet-based architecture of Loquercio et al.
        \begin{itemize}
            \item could process approx. 10 frames per second onboard with their hardware setup
            \item trained by imitating an automatically computed expert policy
        \end{itemize}
    \item high-level control
    \begin{itemize}
        \item input: output of the CNN ($\vec x, v$)
        \item output: minimum jerk trajectory ('state interception trajectory') $t_s$
        \item conversion from two-dimensional normalized image coordinates to three-dimensional local frame coordinates
        \begin{itemize}
            \item back-project along the camera projection ray, derive depth equal to prediction horizon $d$ -> $p_g$
            \item setting $d$ proportional to normalized platform speed $v$ predicted by the CNN
            \item desired quadrotor speed $v_\text{des} = v_\text{max} \cdot v$
            \begin{itemize}
                \item user can control aggressivness of flight by varying $v_\text{max}$
            \end{itemize}
            \item minimum jerk trajectories are computationally efficient
        \end{itemize}
    \end{itemize}
    \item low-level control
    \begin{itemize}
        \item input: output of high-level controller
        \item output: motor commands to track the trajectory
        \item deploy control scheme proposed by Faessler et al.
    \end{itemize}
    \end{itemize} 
\end{itemize}

Training
\begin{itemize}
    \item imitation learning using automatically generated globally optimal trajectories $t_g$ as a source of supervision
    \item $t_g$ created with minimum snap trajectory implementation by Mellinger and Kumar
    \item assumption: location of each gate is known in reference frame
    \item assumption: accurate state estimates with respect to reference frame accessable
    \item expert policy
    \begin{itemize}
        \item given quadrotor position $\vec p_c \in \text{R}^3$ -> compute closest point on the global reference trajectory $\vec p_c'$, 
        compute desired position $\vec p_g$ (point on global trajectory with distance equal to prediction horizon $d\in \text{R}$)
        \item project $\vec p_g$ onto image plane -> ground truth normalized image coordinates $\vec x_g$ corresponding to the goal direction
        \item desired speed $v$ = speed of the global trajectory at $\vec p_c'$ / maximum speed along $t_g$
    \end{itemize}
\end{itemize}

Data
\begin{itemize}
    \item dataset of state estimates and corresponding camera images -> evaluate expert policy to generate ground truth for training
    \item training procedure is agnostic to how exactly the training dataset is collected -> most suitable way of collection
    \begin{itemize}
        \item network is not directly imitating the demonstrated behaviour -> performance of the learned policy is not upper-bounded by the performance
        of the provided demonstrations
    \end{itemize}
    \item "how to deal with the domain shift between training and test time." -> domain shift appears when quadrotor flies far away from $t_g$
    \begin{itemize}
        \item simulation: employed variant of DAgger
        \begin{itemize}
            \item recover expert policy whenever the learned policy deviates far from $t_g$
            \item not feasible for real world: partially trained network controlling an UAV -> high risk of crashing
        \end{itemize}
        \item real world: manually carried the quadrotor through the track, ensuring sufficient coverage of off-trajectory positions
    \end{itemize}
\end{itemize}

Loss function
\begin{itemize}
    \item weighted mean-squared error (MSE) $L = ||\vec x - \vec x_g||^2 + \gamma (v-v_g)^2$
    \begin{itemize}
        \item $\vec x_g$: groundtruth image coordinates
        \item $v_g$: groundtruth speed
    \end{itemize}
    \item by cross-validation: optimal weight $\gamma = 0.1$, performance mostly insensitive to this parameter
\end{itemize}

Dynamic environments
\begin{itemize}
    \item generalization to dynamic tracks
    \begin{itemize}
        \item collect data from a variety of layouts generated by slightly moving the gates from their initial position
        \item generate a global reference trajectory for each layout
        \item train a network jointly on all
    \end{itemize}
    \item additional benefit of improving the robustness of the system.  
\end{itemize}