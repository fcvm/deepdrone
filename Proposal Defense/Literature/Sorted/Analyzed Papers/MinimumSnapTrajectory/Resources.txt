[1]

The last decade has seen many exciting developments in
the area of micro Unmanned Aerial Vehicles that are between
0.1-0.5 meters in length and 0.1-0.5 kilograms in mass
[1].



[2]

In particular, there has been extensive work on multi-
rotor aircrafts, with many recent advances in the design [2] ... for quadrotors ...



[3]

In particular, there has been extensive work on multi-
rotor aircrafts, with many recent advances in ... control [3] ... for quadrotors ...

Some work in this area
has addressed aerobatic maneuvers [3, 6, 9, 10].

While machine learning techniques have
been successful in learning models using data from human
pilots [9] and in improving performance using reinforce-
ment learning [3], these approaches do not appear to lend
themselves to motion planning or trajectory generation in
environments with obstacles.


[4]

In particular, there has been extensive work on multi-
rotor aircrafts, with many recent advances in ... planning [4] for quadrotors ...



[5]

Most of the work in this area uses controllers that are
derived from linearization of the model around hover con-
ditions and are stable only under reasonably small roll
and pitch angles [5].



[6]

Exploring the full state space using
reachability algorithms [6] ... is impractical for a dynamic
system with six degrees of freedom.

Some work in this area
has addressed aerobatic maneuvers [3, 6, 9, 10].



[7]

Exploring the full state space using
... incremental search techniques [7]
... is impractical for a dynamic
system with six degrees of freedom.



[8]

Exploring the full state space using ...
LQR-tree-based searches [8] is impractical for a dynamic
system with six degrees of freedom.



[9]

Some work in this area
has addressed aerobatic maneuvers [3, 6, 9, 10].

While machine learning techniques have
been successful in learning models using data from human
pilots [9] and in improving performance using reinforce-
ment learning [3], these approaches do not appear to lend
themselves to motion planning or trajectory generation in
environments with obstacles.


[10]

Some work in this area
has addressed aerobatic maneuvers [3, 6, 9, 10].



[11]

While machine learning techniques have
been successful in learning models using data from human
pilots [9] and in improving performance using reinforce-
ment learning [3], these approaches do not appear to lend
themselves to motion planning or trajectory generation in
environments with obstacles. Similar problems have been
addressed using model predictive control (MPC) [11, 12].



[12]

While machine learning techniques have
been successful in learning models using data from human
pilots [9] and in improving performance using reinforce-
ment learning [3], these approaches do not appear to lend
themselves to motion planning or trajectory generation in
environments with obstacles. Similar problems have been
addressed using model predictive control (MPC) [11, 12].
With these approaches, guarantees of convergence are only
available when the linearized model is fully controllable [12]
or if a control Lyapunov function can be synthesized [13].



[13]

With these approaches, guarantees of convergence are only
available when the linearized model is fully controllable [12]
or if a control Lyapunov function can be synthesized [13].



[14]

n this section we show that the quadrotor dynamics with
the four inputs is differentially flat [14].



[17]

The cost function in (10) is similar to that used by Flash
and Hogan [17] who showed human reaching trajectories
appear to minimize the integral of the square of the norm
of the jerk (the derivative of acceleration, k r = 3).
